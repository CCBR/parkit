{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"parkit Documentation","text":"<p><code>parkit</code> is a CLI toolkit for archiving CCBR project data to HPC-DME (<code>/CCBR_Archive/GRIDFTP/...</code>).</p> <p>For most users, the recommended interface is <code>projark</code>, which provides guided <code>deposit</code> and <code>retrieve</code> workflows for entire CCBR project folder(s).</p>"},{"location":"#in-this-version-v220-dev","title":"In This Version (<code>v2.2.0-dev</code>)","text":"<ul> <li>New Python-native <code>projark</code> command with structured subcommands.</li> <li><code>projark deposit</code> for project archival with sync/host/session preflight checks.</li> <li><code>projark retrieve</code> with selective file retrieval or full-collection retrieval.</li> <li><code>--unsplit</code> support for merging downloaded split tar parts.</li> <li>Archived legacy bash <code>projark</code> workflow.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>projark --version\nprojark deposit --help\nprojark retrieve --help\n</code></pre>"},{"location":"#recommended-path","title":"Recommended Path","text":"<ol> <li>Complete environment setup from Getting Started.</li> <li>Use projark Deposit (Recommended) to archive data.</li> <li>Use projark Retrieve when you need data back.</li> </ol>"},{"location":"#notes","title":"Notes","text":"<ul> <li><code>projark</code> is intended for Helix (<code>helix.nih.gov</code>).</li> <li>All runs should be executed in <code>tmux</code> or <code>screen</code>.</li> <li>Docs are versioned; this set describes <code>v2.2.0-dev</code> behavior.</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#platform-scope","title":"Platform Scope","text":"<ul> <li>Supported environment: Helix or Biowulf.</li> <li><code>projark</code> workflows are Helix-focused and enforce host checks.</li> </ul>"},{"location":"getting-started/#activate-environment","title":"Activate Environment","text":"<p>If <code>mamba</code> is already in your <code>PATH</code>, run:</p> <pre><code>mamba activate /vf/users/CCBR_Pipeliner/db/PipeDB/miniforge3/envs/parkit\n</code></pre> <p>If <code>mamba</code> is not already in your <code>PATH</code>, add the following block to your <code>~/.bashrc</code> or <code>~/.zshrc</code>:</p> <pre><code># &gt;&gt;&gt; mamba initialize &gt;&gt;&gt;\n# !! Contents within this block are managed by 'mamba shell init' !!\nexport MAMBA_EXE='/vf/users/CCBR_Pipeliner/db/PipeDB/miniforge3/bin/mamba';\nexport MAMBA_ROOT_PREFIX='/vf/users/CCBR_Pipeliner/db/PipeDB/miniforge3';\n__mamba_setup=\"$(\"$MAMBA_EXE\" shell hook --shell zsh --root-prefix \"$MAMBA_ROOT_PREFIX\" 2&gt; /dev/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__mamba_setup\"\nelse\n    alias mamba=\"$MAMBA_EXE\"  # Fallback on help from mamba activate\nfi\nunset __mamba_setup\n# &lt;&lt;&lt; mamba initialize &lt;&lt;&lt;\n</code></pre> <p>Then run:</p> <pre><code>mamba activate /vf/users/CCBR_Pipeliner/db/PipeDB/miniforge3/envs/parkit\n</code></pre>"},{"location":"getting-started/#required-environment","title":"Required Environment","text":"<ul> <li><code>HPC_DME_APIs</code> repository should be available locally. Follow this setup guide: https://ccbr.github.io/HowTos/docs/HPCDME/setup.html</li> <li><code>HPC_DM_UTILS</code> must resolve to <code>&lt;HPC_DME_APIs&gt;/utils</code>.</li> <li><code>HPC_DM_JAVA_VERSION</code> is auto-set on Helix/Biowulf if missing. Minimum required value is <code>23</code> (as of today).</li> </ul>"},{"location":"getting-started/#sync-preflight","title":"Sync Preflight","text":"<p>Before archival/retrieval runs:</p> <pre><code>parkit checkapisync\n</code></pre> <p>If out of sync:</p> <pre><code>parkit syncapi\n</code></pre> <p><code>projark</code> runs this check automatically and blocks if not synced.</p>"},{"location":"getting-started/#session-safety","title":"Session Safety","text":"<p>Run all operations inside <code>tmux</code> or <code>screen</code>:</p> <pre><code>tmux new -s parkit\n# or\nscreen -S parkit\n</code></pre> <p><code>projark deposit</code> and <code>projark retrieve</code> enforce this check.</p>"},{"location":"legacy/","title":"Archived Bash projark","text":"<p>The legacy bash implementation has been archived.</p>"},{"location":"legacy/#archive-location","title":"Archive Location","text":"<p><code>legacy/projark_legacy.sh</code></p>"},{"location":"legacy/#current-entry-point","title":"Current Entry Point","text":"<p><code>projark</code> is now implemented in Python (<code>src/parkit/projark.py</code>).</p>"},{"location":"legacy/#recommendation","title":"Recommendation","text":"<p>Use the Python <code>projark</code> workflows for all new operations.</p>"},{"location":"operations/","title":"Operational Guidance","text":""},{"location":"operations/#session-requirement","title":"Session Requirement","text":"<p>Run all operations in resilient sessions:</p> <pre><code>tmux new -s parkit\n# or\nscreen -S parkit\n</code></pre> <p><code>projark</code> enforces this for both <code>deposit</code> and <code>retrieve</code>.</p>"},{"location":"operations/#scratch-paths","title":"Scratch Paths","text":"<p>Default staging/retrieval base:</p> <p><code>/scratch/$USER/CCBR-&lt;projectnumber&gt;/</code></p> <p>Datatype subfolders (<code>Analysis</code>/<code>Rawdata</code>) are managed automatically.</p>"},{"location":"operations/#split-threshold","title":"Split Threshold","text":"<p><code>projark deposit</code> supports configurable split threshold/chunk size:</p> <pre><code>projark deposit ... --split-size-gb 500\n</code></pre> <p>Default is <code>500</code> GB.</p>"},{"location":"operations/#cleanup-policy","title":"Cleanup Policy","text":"<ul> <li>Default: cleanup enabled after successful deposit.</li> <li>To retain artifacts: <code>--no-cleanup</code>.</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#out-of-sync-error","title":"Out of Sync Error","text":"<p>If Step 1 fails in <code>projark</code>, run:</p> <pre><code>parkit syncapi\n</code></pre> <p>Then rerun your <code>projark</code> command.</p>"},{"location":"troubleshooting/#host-check-failure","title":"Host Check Failure","text":"<p><code>projark</code> requires Helix host identity (<code>helix.nih.gov</code>).</p>"},{"location":"troubleshooting/#session-check-failure","title":"Session Check Failure","text":"<p>If prompted to use <code>tmux</code>/<code>screen</code>, start one and rerun.</p>"},{"location":"troubleshooting/#tokenauth-failures","title":"Token/Auth Failures","text":"<p>If token generation fails during <code>syncapi</code>, verify credentials and inspect:</p> <p><code>HPC_DME_APIs/utils/temp/log</code></p>"},{"location":"troubleshooting/#missing-collectionobject-on-retrieve","title":"Missing Collection/Object on Retrieve","text":"<ul> <li>Validate project number and datatype.</li> <li>Use <code>--filenames</code> only for exact object names.</li> <li>Omit <code>--filenames</code> for full collection retrieval.</li> </ul>"},{"location":"troubleshooting/#split-merge-expectations","title":"Split Merge Expectations","text":"<p><code>--unsplit</code> merges only files matching <code>*.tar_0001</code>, <code>*.tar_0002</code>, etc. If none are present, merge is skipped.</p>"},{"location":"cli/parkit-checkapisync/","title":"parkit checkapisync","text":"<p>Checks whether local <code>HPC_DME_APIs</code> is in sync with upstream.</p>"},{"location":"cli/parkit-checkapisync/#syntax","title":"Syntax","text":"<pre><code>parkit checkapisync [--repo /path/to/HPC_DME_APIs]\n</code></pre>"},{"location":"cli/parkit-checkapisync/#repo-resolution-order","title":"Repo Resolution Order","text":"<ol> <li><code>--repo</code></li> <li><code>HPC_DME_APIs</code> env var</li> <li>Parent of <code>HPC_DM_UTILS</code> if it ends with <code>utils</code></li> <li>Fallback <code>/data/kopardevn/SandBox/HPC_DME_APIs</code></li> </ol>"},{"location":"cli/parkit-checkapisync/#exit-meaning","title":"Exit Meaning","text":"<ul> <li>In sync: safe to proceed.</li> <li>Out of sync: run <code>parkit syncapi</code> before <code>projark</code> operations.</li> </ul> <p><code>projark</code> runs this check as Step 1 in both <code>deposit</code> and <code>retrieve</code>.</p>"},{"location":"cli/parkit-overview/","title":"parkit Overview","text":"<p><code>parkit</code> provides lower-level archival primitives.</p>"},{"location":"cli/parkit-overview/#command-group","title":"Command Group","text":"<pre><code>parkit --help\n</code></pre> <p>Core subcommands:</p> <ul> <li><code>createtar</code></li> <li><code>tarprep</code></li> <li><code>createemptycollection</code></li> <li><code>createmetadata</code></li> <li><code>deposittar</code></li> <li><code>checkapisync</code></li> <li><code>syncapi</code></li> </ul>"},{"location":"cli/parkit-overview/#when-to-use-parkit-directly","title":"When To Use <code>parkit</code> Directly","text":"<ul> <li>You need manual control of each archival step.</li> <li>You are debugging individual data-management operations.</li> <li>You are operating legacy workflows.</li> </ul> <p>For routine project archival/retrieval, use <code>projark</code>.</p>"},{"location":"cli/parkit-syncapi/","title":"parkit syncapi","text":"<p>Syncs local <code>HPC_DME_APIs</code> and refreshes HPC-DME token.</p>"},{"location":"cli/parkit-syncapi/#syntax","title":"Syntax","text":"<pre><code>parkit syncapi [--repo /path/to/HPC_DME_APIs]\n</code></pre>"},{"location":"cli/parkit-syncapi/#what-it-does","title":"What It Does","text":"<ol> <li>Resolves API repo path.</li> <li>Runs <code>git pull</code>.</li> <li>Sources API functions.</li> <li>Runs <code>dm_generate_token</code> interactively.</li> </ol>"},{"location":"cli/parkit-syncapi/#typical-use","title":"Typical Use","text":"<pre><code>parkit checkapisync\nparkit syncapi\nparkit checkapisync\n</code></pre>"},{"location":"cli/projark-deposit/","title":"projark deposit","text":"<p>Archives a local project folder into HPC-DME collection paths under:</p> <p><code>/CCBR_Archive/GRIDFTP/Project_CCBR-&lt;projectnumber&gt;/&lt;datatype&gt;</code></p>"},{"location":"cli/projark-deposit/#syntax","title":"Syntax","text":"<pre><code>projark deposit \\\n  --folder /data/CCBR/projects/CCBR-12345 \\\n  --projectnumber 12345 \\\n  --datatype Analysis\n</code></pre>"},{"location":"cli/projark-deposit/#inputs","title":"Inputs","text":"<ul> <li><code>--folder</code> (required): local folder to archive.</li> <li><code>--projectnumber</code> (required): accepts <code>1234</code>, <code>ccbr1234</code>, <code>CCBR-1234</code>, <code>ccbr_1234</code>.</li> <li><code>--datatype</code> (optional): <code>Analysis</code> (default) or <code>Rawdata</code> (case-insensitive).</li> <li><code>--tarname</code> (optional): override tar filename (default <code>ccbr&lt;projectnumber&gt;.tar</code>).</li> <li><code>--split-size-gb</code> (optional): split threshold/chunk size, default <code>500</code>.</li> <li><code>--cleanup</code> / <code>--no-cleanup</code>: cleanup is enabled by default.</li> </ul>"},{"location":"cli/projark-deposit/#runtime-behavior","title":"Runtime Behavior","text":"<ol> <li>Sync gate (<code>checkapisync</code>)</li> <li>Helix host check</li> <li><code>tmux</code>/<code>screen</code> session check</li> <li>Ensure target collections exist (create as needed)</li> <li>Stage tar + filelist in <code>/scratch/$USER/CCBR-&lt;projectnumber&gt;/&lt;datatype&gt;/</code></li> <li>Split tar if above split threshold</li> <li>Generate <code>.md5</code> for staged files</li> <li>Transfer via <code>dm_register_directory</code></li> <li>Cleanup scratch (default on)</li> </ol>"},{"location":"cli/projark-deposit/#notes","title":"Notes","text":"<ul> <li>Run from a <code>tmux</code> or <code>screen</code> session.</li> <li>For raw data, pass <code>--datatype rawdata</code>.</li> </ul>"},{"location":"cli/projark-overview/","title":"projark Overview","text":"<p><code>projark</code> is the recommended high-level interface for project archival.</p>"},{"location":"cli/projark-overview/#version","title":"Version","text":"<pre><code>projark --version\nprojark deposit --version\nprojark retrieve --version\n</code></pre> <p>All print the same package-aware message.</p>"},{"location":"cli/projark-overview/#subcommands","title":"Subcommands","text":"<ul> <li><code>deposit</code>: archive local folder content to HPC-DME project collection.</li> <li><code>retrieve</code>: retrieve archived data objects back to local scratch.</li> </ul>"},{"location":"cli/projark-overview/#safety-gates","title":"Safety Gates","text":"<p>Both subcommands run preflight checks:</p> <ul> <li><code>parkit checkapisync</code></li> <li>host must be <code>helix.nih.gov</code></li> <li>session must be inside <code>tmux</code> or <code>screen</code></li> </ul>"},{"location":"cli/projark-retrieve/","title":"projark retrieve","text":"<p>Retrieves archived files from:</p> <p><code>/CCBR_Archive/GRIDFTP/Project_CCBR-&lt;projectnumber&gt;/&lt;datatype&gt;</code></p>"},{"location":"cli/projark-retrieve/#syntax","title":"Syntax","text":"<p>Selected files:</p> <pre><code>projark retrieve \\\n  --projectnumber 12345 \\\n  --datatype Analysis \\\n  --filenames new.tar_0001,new.tar_0002 \\\n  --unsplit\n</code></pre> <p>Full collection:</p> <pre><code>projark retrieve --projectnumber 12345 --unsplit\n</code></pre>"},{"location":"cli/projark-retrieve/#inputs","title":"Inputs","text":"<ul> <li><code>--projectnumber</code> (required)</li> <li><code>--datatype</code> (optional, default <code>Analysis</code>)</li> <li><code>--folder</code> (optional): local base folder (default <code>/scratch/$USER/CCBR-&lt;projectnumber&gt;</code>)</li> <li><code>--filenames</code> (optional): comma-separated object names; omit for full collection download</li> <li><code>--unsplit</code> / <code>--unspilt</code>: merge split tar parts after download</li> </ul>"},{"location":"cli/projark-retrieve/#runtime-behavior","title":"Runtime Behavior","text":"<ol> <li>Sync gate (<code>checkapisync</code>)</li> <li>Helix host check</li> <li><code>tmux</code>/<code>screen</code> session check</li> <li>Validate source collection exists</li> <li>Download selected objects (<code>dm_download_dataobject</code>) or full collection (<code>dm_download_collection</code>)</li> <li>Optionally merge <code>*.tar_0001</code>, <code>*.tar_0002</code>, ... into tar files</li> </ol>"},{"location":"cli/projark-retrieve/#merge-behavior","title":"Merge Behavior","text":"<p><code>--unsplit</code> supports multiple split groups in one run.</p>"},{"location":"release-notes/v2.2.0-dev/","title":"Release Notes: v2.2.0-dev","text":""},{"location":"release-notes/v2.2.0-dev/#highlights","title":"Highlights","text":"<ul> <li>Introduced Python-native <code>projark</code> command in package.</li> <li>Added <code>projark deposit</code> and <code>projark retrieve</code> subcommands.</li> <li>Added sync preflight gate (<code>parkit checkapisync</code>) before operations.</li> <li>Added Helix and <code>tmux</code>/<code>screen</code> preflight checks.</li> <li>Added configurable deposit split threshold (<code>--split-size-gb</code>, default <code>500</code>).</li> <li>Added full-collection retrieval mode when <code>--filenames</code> is omitted.</li> <li>Added split-part merge support (<code>--unsplit</code>) across multiple tar groups.</li> <li>Archived legacy bash <code>projark</code> script.</li> </ul>"},{"location":"release-notes/v2.2.0-dev/#behavior-notes","title":"Behavior Notes","text":"<ul> <li><code>projark --version</code>, <code>projark deposit --version</code>, and <code>projark retrieve --version</code> now provide the same package-aware version output.</li> <li>Version-only invocations avoid unrelated bootstrap warnings.</li> </ul>"},{"location":"release-notes/v2.2.0-dev/#migration-notes","title":"Migration Notes","text":"<p>Users previously relying on bash <code>projark</code> should switch to:</p> <ul> <li><code>projark deposit ...</code></li> <li><code>projark retrieve ...</code></li> </ul>"},{"location":"workflows/classic-parkit-manual/","title":"Classic parkit Manual Flow (Legacy)","text":"<p>This is the older manual multi-step path. Prefer <code>projark</code> unless you need step-level control.</p>"},{"location":"workflows/classic-parkit-manual/#sequence","title":"Sequence","text":"<pre><code>parkit createtar --folder /data/CCBR/projects/ccbr_12345\nparkit createemptycollection --dest /CCBR_Archive/GRIDFTP/Project_CCBR-12345 --projectdesc \"testing\" --projecttitle \"test project\"\nparkit createmetadata --tarball /data/CCBR/projects/ccbr_12345.tar --dest /CCBR_Archive/GRIDFTP/Project_CCBR-12345\nparkit deposittar --tarball /data/CCBR/projects/ccbr_12345.tar --dest /CCBR_Archive/GRIDFTP/Project_CCBR-12345\n</code></pre>"},{"location":"workflows/classic-parkit-manual/#why-legacy","title":"Why Legacy","text":"<ul> <li>More manual steps</li> <li>Higher operator overhead</li> <li>Easier to miss preflight/session safeguards that <code>projark</code> includes by default</li> </ul>"},{"location":"workflows/projark-deposit-workflow/","title":"projark Deposit (Recommended)","text":"<p>Use this for standard CCBR project archival.</p>"},{"location":"workflows/projark-deposit-workflow/#example","title":"Example","text":"<pre><code>projark deposit \\\n  --folder /data/CCBR/projects/CCBR-12345 \\\n  --projectnumber CCBR-12345 \\\n  --datatype Analysis\n</code></pre>"},{"location":"workflows/projark-deposit-workflow/#with-custom-tar-name-and-split-threshold","title":"With Custom Tar Name and Split Threshold","text":"<pre><code>projark deposit \\\n  --folder /data/CCBR/projects/CCBR-12345 \\\n  --projectnumber 12345 \\\n  --datatype analysis \\\n  --tarname new.tar \\\n  --split-size-gb 250\n</code></pre>"},{"location":"workflows/projark-deposit-workflow/#keep-scratch-artifacts","title":"Keep Scratch Artifacts","text":"<pre><code>projark deposit ... --no-cleanup\n</code></pre>"},{"location":"workflows/projark-deposit-workflow/#outcome","title":"Outcome","text":"<ul> <li>Data staged in scratch</li> <li>Collection paths created/validated</li> <li>Directory transferred to HPC-DME</li> <li>Scratch cleaned by default</li> </ul>"},{"location":"workflows/projark-retrieve-full/","title":"projark Retrieve Full Collection","text":"<p>When <code>--filenames</code> is omitted, <code>projark</code> downloads the entire datatype collection.</p>"},{"location":"workflows/projark-retrieve-full/#example","title":"Example","text":"<pre><code>projark retrieve --projectnumber 12345 --datatype Analysis --unsplit\n</code></pre>"},{"location":"workflows/projark-retrieve-full/#behavior","title":"Behavior","text":"<ul> <li>Uses <code>dm_download_collection &lt;source-collection&gt; &lt;base-local-folder&gt;</code>.</li> <li>Collection lands at <code>/scratch/$USER/CCBR-12345/Analysis</code> by default.</li> <li><code>--unsplit</code> then scans that datatype folder and merges all split tar groups.</li> </ul>"},{"location":"workflows/projark-retrieve-selected/","title":"projark Retrieve Selected Files","text":"<p>Retrieve specific objects by name.</p>"},{"location":"workflows/projark-retrieve-selected/#example","title":"Example","text":"<pre><code>projark retrieve \\\n  --projectnumber 12345 \\\n  --datatype Analysis \\\n  --filenames new.tar_0001,new.tar_0002,new.tar.filelist \\\n  --unsplit\n</code></pre>"},{"location":"workflows/projark-retrieve-selected/#result","title":"Result","text":"<ul> <li>Requested objects are downloaded to <code>/scratch/$USER/CCBR-12345/Analysis</code> (or custom <code>--folder</code>).</li> <li>If <code>--unsplit</code> is used, matching split tar parts are merged.</li> </ul>"}]}